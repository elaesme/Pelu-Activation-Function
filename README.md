# Pelu-Activation-Function

- Creating a custom PELU activation function using TensorFlow
- Computing gradients 
- Training a classification model with this custom PELU activation function using MNIST data
- Comparing the model with an another model which used ReLu as the activation function with the same dataset
